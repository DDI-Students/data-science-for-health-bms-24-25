---
title: "Tumor Classifier - K-Nearest Neighbours"
author: "Your name"
date: "September 11, 2024"
output: 
  html_document:
    toc: true
    number_sections: true
editor_options: 
  chunk_output_type: inline
---

# Tumour Classifier with K-Nearest Neighbours (KNN)

In this exercise, you'll build a KNN classifier to distinguish between tumor classes based on a subset of features. Complete the steps by filling in the missing code and answering questions.

You will use the `caret` package for this exercise. Use the 'help' in RStudio to discover how they work. The key functions that you will use are:

- createDataPartition
- trainControl
- train
- predict
- confusionMatrix

## Instructions

### Step 1: Install and load necessary libraries

Fill in the missing code to install and load the following libraries: tidyverse, here, and caret.

```{r }
# Install packages if you haven't already
# install.packages("caret")

library(...) 
library(...)
library(...)
```

### Step 2: Load the dataset

```{r load-data}
cancer_data <- read_csv(here("data", "synthetic_cancer_data.csv"))
cancer_data
```

### Step 3: Prepare the data

-   Select the three relevant variables; Perimeter, Concavity, Class
-   Convert the target variable to a factor
-   Split the data into 80% training and 20% testing sets

```{r}

# Keep only the three relevant columns
data_subset <- ... %>% 
  ...(..., ..., ...)

# Encode the target variable as a factor
...$... <- ...(...$...)

... <- ... %>% 
  ...(... = ...(...))
  
# Set a seed for reproducibility
set.seed(42)

# Split the data into training (80%) and testing (20%) sets
train_index <- ...(...$..., p = ..., list = FALSE)

... <- ... %>% 
  ...(...)

... <- ... %>% 
  ...(-...)

```

*Question*: Why is it important to set a seed before splitting the data?

*Answer*: ....

### Step 4: Train the KNN model

-   Define a cross-validation control.
-   Train the KNN model, tuning the number of neighbours 'k' using tuneLength = 10.

```{r}
# Define training control (using 10-fold cross-validation)
trainControl <- ...(..., ... )

# Train the KNN model 
knn_model <- ...(... ~ ., 
                 data = ..., 
                 ... = ...,
                 ... = ...,
                 ... = ...,
                 ... = ...,
                 ... = ...)

# View the results
knn_model

```

*Question*: What is the purpose of using cross-validation when training the model?

*Answer*: ...

### Step 5: Make predictions

-   Use the trained model to predict on the test data.
-   Assess the performance using a confusion matrix.

```{r}
# Make predictions on the test set
predictions <- ...(..., ... = ...)

# Confusion matrix  
...(..., ...$...)

```

*Question*: What insights can you gather from the confusion matrix? Is the model performing well?

*Answer*: ...

### Step 6: Tune the model (optional)

-   Explore the best value of 'k' from the trained model.
-   Discuss how the number of neighbors (k) impacts model performance.

```{r}
# Check the best value of 'k'
... <- ...$...
print(...)
```

*Question*: What is the optimal value of 'k'? How would you explain its significance?

*Answer*: ...
